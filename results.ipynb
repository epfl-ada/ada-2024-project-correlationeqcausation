{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:24:44.247928Z",
     "start_time": "2024-11-15T11:24:44.245226Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe3fbd",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1927a724623b47",
   "metadata": {},
   "source": [
    "## How datasets are joined\n",
    "\n",
    "### Movie dataset and Character dataset\n",
    "We join the two datasets on the `freebase_movie_id`.\n",
    "\n",
    "### Character dataset and Oscar dataset\n",
    "Oscar dataset does not have `freebase_movie_id` or `freebase_actor_id`. We instead use `parsed_actor_name` and `movie_identifier`. `parsed_actor_name` will be unique for each movie as we drop actors if they share `parsed_actor_name` from playing another character in the same movie. `movie_identifier` is a combination of `parsed_movie_name` and `release_year`. This is unique as we drop movies that share `movie_identifier`.\n",
    "\n",
    "### Resulting dataset from previous steps and IMDb dataset\n",
    "We join these datasets using a combination of `parsed_movie_name` and `release_year` as primary key.\n",
    "<br><br><br>\n",
    "The resulting dataset after the entire pipeline is run is written to `cache/data.csv`, ready for use in P3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2309d2c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:25:31.018305Z",
     "start_time": "2024-11-15T11:24:44.261753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Data pipeline ##########\n",
      "\n",
      "Preparing CMU data\n",
      "379 movies shared both name and release year, dropping\n",
      "314 movies had actors with the same name, dropping\n",
      "\n",
      "Merging Oscar dataset, after merge:\n",
      "Number of different Oscar nominated movies in dataset: 952 in total 63968 different movies\n",
      "Number of different Oscar nominated actors in dataset: 801 in total 134907 different actors\n",
      "Number of Oscar nominated rows: 1443\n",
      "\n",
      "Merging IMDb dataset, after merge:\n",
      "Number of movies with ratings: 36758\n",
      "Oscar nominated movies with rating: 939\n",
      "Number of rows in data before cleaning:  443504\n",
      "Number of rows in data after cleaning:  23819\n",
      "Number of rows where age is < 0: 7 . Dropping these rows\n",
      "\n",
      "FINAL STATE OF DATA\n",
      "Number of rows:  23812\n",
      "Number of different Oscar nominated movies in dataset: 394 in total 5987 different movies\n",
      "Number of different Oscar nominated actors in dataset: 284 in total 2959 different actors\n",
      "Number of Oscar nominated rows: 519\n",
      "Processing done, dataset written to cache/data.csv\n"
     ]
    }
   ],
   "source": [
    "%run data_pipeline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd2a4f09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:25:32.927001Z",
     "start_time": "2024-11-15T11:25:31.648108Z"
    }
   },
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv('cache/data.csv', sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee5d7ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>box_office_revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_identifier</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>actor_height</th>\n",
       "      <th>actor_ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>identifier</th>\n",
       "      <th>category</th>\n",
       "      <th>winner</th>\n",
       "      <th>oscar_nominated</th>\n",
       "      <th>year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>number_of_votes</th>\n",
       "      <th>number_of_movies_starred_in</th>\n",
       "      <th>average_rating_previous_movies</th>\n",
       "      <th>average_box_office_revenue_previous_movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140029</th>\n",
       "      <td>Down to You</td>\n",
       "      <td>24419914</td>\n",
       "      <td>92</td>\n",
       "      <td>['French Language', 'English Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Romantic comedy', 'Romance Film', 'Drama', '...</td>\n",
       "      <td>down to you_2000</td>\n",
       "      <td>M</td>\n",
       "      <td>1.88</td>\n",
       "      <td>/m/0xnvg</td>\n",
       "      <td>...</td>\n",
       "      <td>down to you_2000_adam carolla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15878</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24419914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60320</th>\n",
       "      <td>The Bible: In The Beginning</td>\n",
       "      <td>34900023</td>\n",
       "      <td>171</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United States of America', 'Italy']</td>\n",
       "      <td>['Christian film', 'Drama', 'Epic', 'World cin...</td>\n",
       "      <td>the bible in the beginning_1966</td>\n",
       "      <td>M</td>\n",
       "      <td>1.85</td>\n",
       "      <td>/m/03bkbh</td>\n",
       "      <td>...</td>\n",
       "      <td>the bible in the beginning_1966_richard harris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1966</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6385</td>\n",
       "      <td>1</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>34900023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389034</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>34562222</td>\n",
       "      <td>161</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Period piece', 'Roadshow theatrical release'...</td>\n",
       "      <td>hawaii_1966</td>\n",
       "      <td>M</td>\n",
       "      <td>1.85</td>\n",
       "      <td>/m/03bkbh</td>\n",
       "      <td>...</td>\n",
       "      <td>hawaii_1966_richard harris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1966</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3708</td>\n",
       "      <td>1</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>69462245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130002</th>\n",
       "      <td>Camelot</td>\n",
       "      <td>31102578</td>\n",
       "      <td>178</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Costume drama', 'Musical', 'Roadshow theatri...</td>\n",
       "      <td>camelot_1967</td>\n",
       "      <td>M</td>\n",
       "      <td>1.85</td>\n",
       "      <td>/m/03bkbh</td>\n",
       "      <td>...</td>\n",
       "      <td>camelot_1967_richard harris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1967</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7624</td>\n",
       "      <td>2</td>\n",
       "      <td>9.650000</td>\n",
       "      <td>50282411.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182566</th>\n",
       "      <td>Caprice</td>\n",
       "      <td>4075000</td>\n",
       "      <td>95</td>\n",
       "      <td>['English Language']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['Romantic comedy', 'Crime Fiction', 'Mystery'...</td>\n",
       "      <td>caprice_1967</td>\n",
       "      <td>M</td>\n",
       "      <td>1.85</td>\n",
       "      <td>/m/03bkbh</td>\n",
       "      <td>...</td>\n",
       "      <td>caprice_1967_richard harris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1967</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1761</td>\n",
       "      <td>3</td>\n",
       "      <td>8.266667</td>\n",
       "      <td>34879941.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  box_office_revenue  runtime  \\\n",
       "140029                  Down to You            24419914       92   \n",
       "60320   The Bible: In The Beginning            34900023      171   \n",
       "389034                       Hawaii            34562222      161   \n",
       "130002                      Camelot            31102578      178   \n",
       "182566                      Caprice             4075000       95   \n",
       "\n",
       "                                      languages  \\\n",
       "140029  ['French Language', 'English Language']   \n",
       "60320                      ['English Language']   \n",
       "389034                     ['English Language']   \n",
       "130002                     ['English Language']   \n",
       "182566                     ['English Language']   \n",
       "\n",
       "                                    countries  \\\n",
       "140029           ['United States of America']   \n",
       "60320   ['United States of America', 'Italy']   \n",
       "389034           ['United States of America']   \n",
       "130002           ['United States of America']   \n",
       "182566           ['United States of America']   \n",
       "\n",
       "                                                   genres  \\\n",
       "140029  ['Romantic comedy', 'Romance Film', 'Drama', '...   \n",
       "60320   ['Christian film', 'Drama', 'Epic', 'World cin...   \n",
       "389034  ['Period piece', 'Roadshow theatrical release'...   \n",
       "130002  ['Costume drama', 'Musical', 'Roadshow theatri...   \n",
       "182566  ['Romantic comedy', 'Crime Fiction', 'Mystery'...   \n",
       "\n",
       "                       movie_identifier actor_gender  actor_height  \\\n",
       "140029                 down to you_2000            M          1.88   \n",
       "60320   the bible in the beginning_1966            M          1.85   \n",
       "389034                      hawaii_1966            M          1.85   \n",
       "130002                     camelot_1967            M          1.85   \n",
       "182566                     caprice_1967            M          1.85   \n",
       "\n",
       "       actor_ethnicity  ...                                      identifier  \\\n",
       "140029        /m/0xnvg  ...                   down to you_2000_adam carolla   \n",
       "60320        /m/03bkbh  ...  the bible in the beginning_1966_richard harris   \n",
       "389034       /m/03bkbh  ...                      hawaii_1966_richard harris   \n",
       "130002       /m/03bkbh  ...                     camelot_1967_richard harris   \n",
       "182566       /m/03bkbh  ...                     caprice_1967_richard harris   \n",
       "\n",
       "       category winner oscar_nominated  year average_rating  number_of_votes  \\\n",
       "140029      NaN    NaN           False  2000            5.0            15878   \n",
       "60320       NaN    NaN           False  1966            6.2             6385   \n",
       "389034      NaN    NaN           False  1966            6.5             3708   \n",
       "130002      NaN    NaN           False  1967            6.6             7624   \n",
       "182566      NaN    NaN           False  1967            5.5             1761   \n",
       "\n",
       "        number_of_movies_starred_in  average_rating_previous_movies  \\\n",
       "140029                            1                        5.000000   \n",
       "60320                             1                        6.200000   \n",
       "389034                            1                       12.700000   \n",
       "130002                            2                        9.650000   \n",
       "182566                            3                        8.266667   \n",
       "\n",
       "        average_box_office_revenue_previous_movies  \n",
       "140029                                  24419914.0  \n",
       "60320                                   34900023.0  \n",
       "389034                                  69462245.0  \n",
       "130002                                  50282411.5  \n",
       "182566                                  34879941.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f41dcc",
   "metadata": {},
   "source": [
    "## Descriptive statistics and data limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a9e9eb",
   "metadata": {},
   "source": [
    "### NaN-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3500cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values in each column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "title                                          0.000000\n",
       "box_office_revenue                             0.000000\n",
       "runtime                                        0.000000\n",
       "languages                                      0.000000\n",
       "countries                                      0.000000\n",
       "genres                                         0.000000\n",
       "movie_identifier                               0.000000\n",
       "actor_gender                                   0.000000\n",
       "actor_height                                   0.000000\n",
       "actor_ethnicity                                0.000000\n",
       "actor_age                                      0.000000\n",
       "parsed_actor_name                              0.000000\n",
       "actor_identifier                               0.000000\n",
       "identifier                                     0.000000\n",
       "category                                      97.820427\n",
       "winner                                        97.820427\n",
       "oscar_nominated                                0.000000\n",
       "year                                           0.000000\n",
       "average_rating                                 0.000000\n",
       "number_of_votes                                0.000000\n",
       "number_of_movies_starred_in                    0.000000\n",
       "average_rating_previous_movies                 0.000000\n",
       "average_box_office_revenue_previous_movies     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Percentage of NaN values in each column:')\n",
    "movie_df.isnull().sum() * 100 / len(movie_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e28451",
   "metadata": {},
   "source": [
    "Some columns are critical, yet have high share of NaN values, e.g. actor_ethnicity and box_office_revenue \n",
    "\n",
    "We have asked TAs for input on how to handle these values, we see two options:\n",
    "1. Make a fully cleaned dataset with no NaNs\n",
    "2. Have different subsets of data for different analysis questions\n",
    "\n",
    "Two columns are specific to rows that have been Oscar nominated (category, winner). It is therefore no problem that they have many NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab043e0",
   "metadata": {},
   "source": [
    "We examine how much of the data would be lost if we drop all rows with NaN-values in relevant columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7077fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points before dropping NaN values: 23812\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of data points before dropping NaN values: {len(movie_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f177a55d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['release_date', 'actor_name', 'has_rating']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0y/ghdjhlvn38sf02nh2qxl20_c0000gn/T/ipykernel_48391/3257997799.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data_points_after_drop = len(movie_df.dropna(subset=['title', 'release_date', 'box_office_revenue', 'runtime', 'languages',\n\u001b[0m\u001b[1;32m      2\u001b[0m        \u001b[0;34m'countries'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genres'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'movie_identifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actor_gender'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m        \u001b[0;34m'actor_height'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actor_ethnicity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actor_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actor_age'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0;34m'parsed_actor_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actor_identifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'identifier'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'has_rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average_rating'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6666\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6667\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6670\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ['release_date', 'actor_name', 'has_rating']"
     ]
    }
   ],
   "source": [
    "data_points_after_drop = len(movie_df.dropna(subset=['title', 'release_date', 'box_office_revenue', 'runtime', 'languages',\n",
    "       'countries', 'genres', 'movie_identifier', 'actor_gender',\n",
    "       'actor_height', 'actor_ethnicity', 'actor_name', 'actor_age',\n",
    "       'parsed_actor_name', 'actor_identifier', 'identifier','year', 'has_rating', 'average_rating',\n",
    "       'number_of_votes']))\n",
    "\n",
    "print(f'Number of complete data points we would have if we dropped all NaN values in relevant columns: {data_points_after_drop}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817428b7",
   "metadata": {},
   "source": [
    "We see that a significant portion of the data (~95%) would be lost by removing rows with relevant NaN-values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee0ec6",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffbeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['oscar_nominated', 'number_of_votes', 'average_rating', 'actor_height', 'runtime', 'box_office_revenue']\n",
    "numerical_df = movie_df[cols].dropna()\n",
    "print('Nr. of datapoints in the correlation analysis', len(numerical_df))\n",
    "numerical_df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03800f6",
   "metadata": {},
   "source": [
    "Most entries in the correlation matrix are positive. The ones that are negative are small. \n",
    "\n",
    "Below we analyze the p-value for the correlation to see between which relations it is significant and between which it is not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c6a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating p-values and storing them in the lists 'significant' and 'insignificant' depending on the test outcome. \n",
    "p_values_matrix = []\n",
    "insignificant = []\n",
    "significant = []\n",
    "for col1 in cols: \n",
    "    p_values_list = []\n",
    "    for col2 in cols: \n",
    "        if pearsonr(numerical_df[col1], numerical_df[col2])[1] > (0.05 / 30):  # 95% confidence level adjusted to bonferroni correction \n",
    "            insgnificant.append((col1, col2))\n",
    "        else: \n",
    "            significant.append((col1, col2))\n",
    "            \n",
    "\n",
    "# Printing findings: \n",
    "print(len(significant) - len(cols), 'entries in correlation matrix have significant p-value') # Removing self-correlation\n",
    "print(len(insignificant), 'entries in correlation matrix have insignificant p-value')\n",
    "print()\n",
    "\n",
    "# Printing significant column pairs and skipping self-relations. \n",
    "print('Significant pairs: ')\n",
    "for significant_pair in significant: \n",
    "    if significant_pair[0] != significant_pair[1]:\n",
    "        print(significant_pair[0],'&', significant_pair[1])\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Printing insignificant column pairs\n",
    "print('Insignificant pairs: ')\n",
    "for insignificant_pair in insignificant: \n",
    "    print(insignificant_pair[0], '&', insignificant_pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d573474",
   "metadata": {},
   "source": [
    "The above result indicates that we believe 18 of 30 of the entries in the correlation matrix to be significant at the 95% level. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda7859",
   "metadata": {},
   "source": [
    "# Country/nomination analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_character_oscar_rating_df contains a row for each actor/movie pair. We select the non-American actors and compare with the American actors\n",
    "\n",
    "# All actors/movie rows, American and non-American\n",
    "total_actors_num = len(movie_df['countries'])\n",
    "american_total_actors_num = len(movie_df[movie_df['countries'].str.contains('United States of America')])\n",
    "non_american_total_actors_num = total_actors_num - american_total_actors_num\n",
    "\n",
    "# All actors/movie rows with an Oscar nomination, American and non-American\n",
    "total_nominated_actors_num = len(movie_df[movie_df['oscar_nominated'] == True]['countries'])\n",
    "american_nominations_num = len(movie_df[(movie_df['countries'].str.contains('United States of America')) & (movie_df['oscar_nominated'] == True)])\n",
    "non_american_nominations_num = total_nominated_actors_num - american_nominations_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed probability of American actor getting nominated for a film\n",
    "p_american = american_nominations_num / american_total_actors_num\n",
    "p_non_american = non_american_nominations_num / non_american_total_actors_num\n",
    "\n",
    "# We perform a two-sided hypothesis test for whether non-American actors have the same binomial probability of getting nominated as American ones\n",
    "stats.binomtest(non_american_nominations_num, non_american_total_actors_num, p_american)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e369ac",
   "metadata": {},
   "source": [
    "Using alpha=0.05. P-value=2.6118071094409342e-307 < 0.05. We can safely discard the null hypothesis that these have the same probability distribution, and conclude that there is a significantly different probability of being nominated for an Oscar for American and non-American actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecccb059",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fraction of American actors nominated for an Oscar:',round(p_american, 5))\n",
    "print('Fraction of non-American actors nominated for an Oscar:', round(p_non_american, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1d261",
   "metadata": {},
   "source": [
    "We see that the observed probability of being nominated is higher for actors in American movies. We believe based on this analysis that the Oscar nominations are generally skewed with higher chances for actors in American movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2de70",
   "metadata": {},
   "source": [
    "# Logistic regression on movie and actor traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06834535",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd54a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the most common ethnicities\n",
    "movie_df.groupby('actor_ethnicity').count().sort_values(by='title', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most frequent ethnicities, in descending order.\n",
    "# Found the mappings manually, by looking the Freebase ethnicity ids up.\n",
    "\n",
    "# An alternate solution would probably be to download a Freebase data dump and join using that.\n",
    "# However, the dataset is quite large so we chose to go this route instead.\n",
    "ethnicity_map = {    \n",
    "    'Indian' : '/m/0dryh9k',\n",
    "    'Black' : '/m/0x67',\n",
    "    'Jewish' : '/m/041rx', \n",
    "    'English' : '/m/02w7gg',\n",
    "    'Irish_Americans' : '/m/033tf_',\n",
    "    'Italian_Americans' : '/m/0xnvg',\n",
    "    'White_people' : '/m/02ctzb',\n",
    "    'White_Americans' : '/m/07hwkr',\n",
    "    'Scottish_Americans': '/m/07bch9',\n",
    "    # '???' : '/m/044038p', Could not find what this Freebase id maps to\n",
    "    'Irish_people' : '/m/03bkbh',\n",
    "    'British' : '/m/0d7wh',\n",
    "    'French' : '/m/03ts0c',\n",
    "    'Italians' : '/m/0222qb',\n",
    "    'Tamil' : '/m/01rv7x',   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5db19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We normalize the data before performing logistic regression\n",
    "def normalize_column(df_column):\n",
    "    return (df_column - df_column.mean()) / df_column.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_movie_df = movie_df.copy(deep=True)\n",
    "features_to_normalize = ['actor_age', 'box_office_revenue', 'runtime', 'actor_height', 'year', 'average_rating', 'number_of_votes',]\n",
    "normalized_movie_df[features_to_normalize] = normalized_movie_df[features_to_normalize].apply(normalize_column)\n",
    "\n",
    "# Encode oscar_nominated as 0 or 1 for logistic regression\n",
    "normalized_movie_df['oscar_nominated'] = normalized_movie_df['oscar_nominated'].astype(int)\n",
    "\n",
    "# One-hot encoding the 5 most frequent ethnicities for the logistic regression:\n",
    "ethnicities = list(ethnicity_map.keys())[:5]\n",
    "for name in ethnicities:\n",
    "    normalized_movie_df[name] = normalized_movie_df['actor_ethnicity'].map(lambda ethnicity: 1 if ethnicity == ethnicity_map[name] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following regression and plotting code was inspired and/or copied from the solution to exercise 4\n",
    "# We perform logistic regression using a selection of relevant features from the dataframe\n",
    "mod = smf.logit(formula='oscar_nominated ~  runtime + box_office_revenue + actor_height + \\\n",
    "                        actor_age + year + average_rating + number_of_votes + \\\n",
    "                        C(Indian) + C(Black) + C(Jewish) + C(English) + C(Irish_Americans)', data=normalized_movie_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f9cd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model and print results\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f560f-ebd6-4ab0-8cc1-66e6401a1969",
   "metadata": {},
   "source": [
    "Note: we get the runtime warning as 1+np.exp(-X) gets so massive it is not computed properly. It does not have impact on the output which will be 0 anyways (division by a very large number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature names\n",
    "variables = res.params.index\n",
    "\n",
    "# quantifying uncertainty!\n",
    "\n",
    "# coefficients\n",
    "coefficients = res.params.values\n",
    "\n",
    "# p-values\n",
    "p_values = res.pvalues\n",
    "\n",
    "# standard errors\n",
    "standard_errors = res.bse.values\n",
    "\n",
    "#confidence intervals\n",
    "res.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort them all by coefficients\n",
    "l1, l2, l3, l4 = zip(*sorted(zip(coefficients[1:], variables[1:], standard_errors[1:], p_values[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe28cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.errorbar(l1, np.array(range(len(l1))), xerr= 2*np.array(l3), linewidth = 1,\n",
    "             linestyle = 'none',marker = 'o',markersize= 3,\n",
    "             markerfacecolor = 'black',markeredgecolor = 'black', capsize= 5)\n",
    "\n",
    "plt.vlines(0,0, len(l1), linestyle = '--')\n",
    "\n",
    "plt.yticks(range(len(l2)),l2)\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic regression coefficient by feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ae323",
   "metadata": {},
   "source": [
    "Lines around the points represent the confidence interval for the coefficient of each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9a616df340add",
   "metadata": {},
   "source": [
    "From this plot we see that there are multiple factors that can be used to predict whether a movie/actor row will be nominated or not. This serves as an initial analysis, we will do this more thoroughly in P3 to make more relevant conclusions for our research questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50e0f3",
   "metadata": {},
   "source": [
    "# Review analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97042b70",
   "metadata": {},
   "source": [
    "To extract movies with nominated actors we need to find every movie where at least one of the rows in the column 'oscar_nominated' is positive.\n",
    "To extract movies without a nominated actor we need to find every movie where every row in the column 'oscar_nominated' is false. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping all movies by title, into unique_movies_df\n",
    "unique_movies_df = movie_df.groupby('movie_identifier').first().reset_index()\n",
    "\n",
    "print('Shape before: ', unique_movies_df.shape)\n",
    "unique_nominated_movies_df = movie_df[movie_df['oscar_nominated'] == True].groupby('movie_identifier').first().reset_index()\n",
    "# Mask is true if a movie from unique_movies_df is not in the dataframe unique_nominated_movies_df\n",
    "mask = unique_movies_df['movie_identifier'].isin(unique_nominated_movies_df['movie_identifier']) == False\n",
    "\n",
    "# Applying the mask \n",
    "not_nominated_df = unique_movies_df[mask]\n",
    "# Checking the intersection between nominated and not nominated movies, should be 0 \n",
    "print('Intersection between nominated and not nominated: ', pd.Series(list(set(unique_nominated_movies_df['movie_identifier']).intersection(set(not_nominated_df['movie_identifier'])))))\n",
    "\n",
    "unique_movies_df = pd.concat([unique_nominated_movies_df, not_nominated_df], axis = 0) \n",
    "print('Shape after: ', unique_movies_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049dbc8",
   "metadata": {},
   "source": [
    "Intersection is [], hence selection worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing movies without imdb ratings\n",
    "movie_unique_with_rating_df = unique_movies_df[unique_movies_df['average_rating'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e85066",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Movies with oscar nominated actors with ratings: ', len(movie_unique_with_rating_df[movie_unique_with_rating_df['oscar_nominated'] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d87ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting nominated and movies and not nominated movies \n",
    "nominated = movie_unique_with_rating_df[movie_unique_with_rating_df['oscar_nominated']]\n",
    "not_nominated = movie_unique_with_rating_df[movie_unique_with_rating_df['oscar_nominated'] == False]\n",
    "assert nominated.shape[0] + not_nominated.shape[0] == movie_unique_with_rating_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e87775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We exclude all movies with fewer than 30 reviews. There are no movies with oscar nominated actors with fewer than 30 reviews.\n",
    "# This is based on a rule of thumb to exclude outliers / low confidence values \n",
    "excluded = not_nominated[not_nominated['number_of_votes'] < 30]\n",
    "print('Excluded nr of movies from analysis due to few reviews (< 30): ', len(excluded))\n",
    "not_nominated = not_nominated[not_nominated['number_of_votes'] >= 30]\n",
    "nominated = nominated[nominated['number_of_votes'] >= 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical CDF for nominated and not nominated \n",
    "\n",
    "sns.histplot(nominated, x=\"average_rating\", stat = 'density', color = 'gold',label ='Nominated', bins =40)\n",
    "sns.histplot(not_nominated, x=\"average_rating\", stat=\"density\", color = 'grey', label = 'Not nominated', bins = 50)\n",
    "\n",
    "plt.title('Rating distribution of movies')\n",
    "plt.xlabel('IMDB rating')\n",
    "plt.ylabel('Probability density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4c9a3",
   "metadata": {},
   "source": [
    "These empirical distributions look different. We use a two sample Kolmogorov-Smirnov test to test if they are different. The null hypothesis is that the observations come from the same distribution. We reject the null hypothesis if the p-value < 0.05. Also we note that if the test statistic is 0 the distributions are identical and if the test statistic is 1 the distributions are completely different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b8752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:26:33.947220162Z",
     "start_time": "2024-11-15T10:30:21.517393Z"
    }
   },
   "outputs": [],
   "source": [
    "stats.kstest(nominated['average_rating'], not_nominated['average_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e23719",
   "metadata": {},
   "source": [
    "Test statistic is 0.55, meaning distributions are different but not completely different. \n",
    "P-value = 1.6450047550532477e-259. This is extremely small, we can safely reject the null hypothesis. The conclusion is that the distributions are in fact different distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8104702e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:26:33.948110156Z",
     "start_time": "2024-11-15T10:30:22.084555Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting reviews per IMDB reviews per movie \n",
    "sns.histplot(not_nominated, x=\"number_of_votes\", bins=50, label = 'Not nominated', color = 'grey')\n",
    "sns.histplot(nominated, x=\"number_of_votes\", bins=50, label = 'Nominated', color = 'gold')\n",
    "plt.yscale('log')\n",
    "plt.title('Review distribution')\n",
    "plt.xlabel('Reviews per movie (millions)')\n",
    "plt.ylabel('Nr. of movies (log)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kstest(not_nominated['number_of_votes'], nominated['number_of_votes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2da46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:26:33.948325120Z",
     "start_time": "2024-11-15T10:30:22.552151Z"
    }
   },
   "outputs": [],
   "source": [
    "# As per the plot above, most movies with nominated actors have fewer than 500 000 reviews.\n",
    "# We zoom in and look at the movies with few reviews. \n",
    "\n",
    "lim_not_nominated = not_nominated[not_nominated['number_of_votes'] < 10000]\n",
    "lim_nominated = nominated[nominated['number_of_votes'] < 10000]\n",
    "\n",
    "print('Share of not nominated movies with fewer than 10 000 reviews:', round(len(lim_not_nominated)/len(not_nominated)*100,2), '%')\n",
    "print('Share of nominated with fewer than 10 000 reviews:', round(len(lim_nominated)/(len(nominated))*100,2),  '%')\n",
    "\n",
    "sns.histplot(lim_not_nominated, x=\"number_of_votes\", bins=50, label = 'Not nominated', color = 'grey')\n",
    "sns.histplot(lim_nominated, x=\"number_of_votes\", bins=50, label = 'Nominated', color = 'gold')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.title('Reviews per movie')\n",
    "plt.xlabel('Reviews')\n",
    "plt.ylabel('Nr. of movies (log)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f47d6",
   "metadata": {},
   "source": [
    "We can see that most movies with relatively few review are not nominated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db98b35",
   "metadata": {},
   "source": [
    "## Box-Office Revenue\n",
    "\n",
    "Note: we will inflation adjust box-office revenues in P3 for higher accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4125cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:26:33.948528301Z",
     "start_time": "2024-11-15T10:30:23.647085Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(not_nominated, x=\"box_office_revenue\", stat=\"density\", color = 'grey', label = 'Not nominated', bins = 60)\n",
    "sns.histplot(nominated, x=\"box_office_revenue\", stat = 'density', color = 'gold',label ='Nominated', bins = 40)\n",
    "\n",
    "plt.title('Box office revenue distribution')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Box-office revenue (billions) ')\n",
    "plt.ylabel('Probability density (log)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f74dc",
   "metadata": {},
   "source": [
    "Notice that the above plot is a probability distribution and that the y-axis is in log scale. We are surprised since all movies with nominated actors do not seem to be the ones with the highest revenue. To investigate this we look into movies with lower box-office revenue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5bd63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:26:33.948706094Z",
     "start_time": "2024-11-15T10:30:24.598682Z"
    }
   },
   "outputs": [],
   "source": [
    "lim_not_nominated = not_nominated[not_nominated['box_office_revenue'] < 10**7]\n",
    "lim_nominated = nominated[nominated['box_office_revenue'] < 10**7]\n",
    "\n",
    "sns.histplot(lim_not_nominated, x=\"box_office_revenue\", stat=\"density\", color = 'grey', label = 'Not nominated', bins = 20)\n",
    "sns.histplot(lim_nominated, x=\"box_office_revenue\", stat = 'density', color = 'gold',label ='Nominated', bins = 20)\n",
    "\n",
    "plt.title('Box office revenue distribution for movies with revenue less than 10**7')\n",
    "plt.xlabel('Box-office revenue (10s of millions)')\n",
    "plt.ylabel('Probability density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde0f513",
   "metadata": {},
   "source": [
    "We can see that movies with nominated actors have revenue in an interval. They are neither the movies with the highest revenue, or the movies with the lowest revenue. We think this will be a hypothesis to explore further in P3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
